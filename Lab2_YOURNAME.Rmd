---
title: 'Week 4 (LAB2): Sampling designs and statistical bias'
subtitle: "PSTAT100: Data Science Concepts and Analysis" 

author:
  - name: "YOUR NAME"
    affiliations
      - name: "Spring 2025"
affiliation-title: "Quarter"
format: 
 pdf:

    code-fold: true
    code-line-numbers: true
    code-copy: true
    code-tools: true
    self-contained: true
    toc: false
    toc-location: left
    number-sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message =  FALSE)
knitr::opts_chunk$set(warning =  FALSE)
knitr::opts_chunk$set(error =  FALSE)
bfcolor <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{\\textbf{%s}}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'><b>%s</b></span>", color, x)
  } else x
}
```



# Submission Instructions


* This LAB must be completed and submitted **individually**. Collaboration is allowed for discussion, but each student must submit their own work.

* Ensure that all `R` code are presented clearly and appropriately.

* All figures should be numbered, and axes must be labeled. 

* Please use the provided `LAB 2.qmd` file to type your solutions and submit the completed LAB as a PDF file. You can utilize `RStudio` for this purpose. For guidance, refer to the [Tutorial: Hello, Quarto](https://quarto.org/docs/get-started/hello/rstudio.html)).

* Submit your solution via **Gradescope**.


# Due Date
**Due Date:** Thursday, April 24, 2025, 11:59 PM



# Overview
In this lab you'll explore through simulation how nonrandom sampling can produce datasets with statistical properties that are distorted relative to the population that the sample was drawn from. This kind of distortion is known as **bias**. 

## Objectives:

* Simulate biased and unbiased sampling designs
* Examine the impact of sampling bias on the sample mean
* Apply a simple bias correction by inverse probability weighting

## Background

### Sampling designs

The **sampling design** of a study refers to _**the way observational units are selected**_ from the collection of all observational units. Any design can be expressed by the probability that each unit is included in the sample. In a random sample, all units are equally likely to be included.

### Bias

Formally, **bias** describes _**the 'typical' deviation of a sample statistic from the corresponding population value**_. 

## Simulated data

You will be simulating data in this lab. **Simulation** is a great means of exploration _**because you can control the population properties**_, which are generally unknown in practice. 

# Scenario 1: eucalyptus seed diameters

## Hypothetical population

To provide a little context to this scenario, imagine that you're measuring eucalyptus seeds to determine their typical diameter. The cell below simulates diameter measurements for a hypothetical population of 5000 seeds; imagine that this is the total number of seeds in a small grove at some point in time.

```{r}
# simulate seed diameters
#Density, distribution function, quantile function and random generation for the Gamma distribution with parameters shape and scale.
set.seed(40221) # for reproducibility
population <- data.frame(
  diameter = rgamma(5000, shape = 2, scale = 1/2),
  seed = 1:5000
)

# check first few rows
head(population, 3)
```


# **Question 1**    (2 Point)

Calculate the mean diameter for the hypothetical population.

```{r}
#this is us computing the mean of the seed diameter using the mean function
mean_pop_dia<- mean(population$diameter)

#this is me printing our findings
mean_pop_dia
```


# **Question 2**    (2 Point)

Calculate the standard deviation of diameters for the hypothetical population.

```{r}
#this is us using the sd function to determine the standard deviation of the seeds 
sd_pop_dia<- sd(population$diameter)

#this is me printing my findings
sd_pop_dia
```

The cell below produces a histogram of the population values -- the distribution of diameter measurements among the hypothetical population -- with a vertical line indicating the population mean.

```{r, message=FALSE, warning=FALSE}
# Plot population distribution
# Make sure to install ggplot2 in your console! 
library(ggplot2)
#this is us calculating the mean for the seed diameter and assigning the value to the mean_pop_diameter object
mean_pop_diameter <- mean(population$diameter)

#this is us using ggplot to create a plot! 
# remember to start with the name of the data followed by the aesthetics (aes) argument to tell R what variables are being plotted on x- and y- axes. Any additional features to add to the basic plot, like nodes to represent the data points, use the addition symbol. Please, look at all of the ggplot options! https://rstudio.github.io/cheatsheets/data-visualization.pdf
ggplot(population, aes(x = diameter)) +
  geom_histogram(bins = 20, alpha = 0.8) +
  geom_vline(xintercept = mean_pop_diameter, color = "blue") +
  labs(x = "Diameter (mm)", y = "Number of seeds in population") +
  xlim(0, 6)
```

## Random sampling

Imagine that your sampling design involves collecting bunches of plant material from several locations in the grove and sifting out the seeds with a fine sieve until you obtaining 250 seeds. We'll suppose that using your collection method, any of the 5000 seeds is equally likely to be obtained, so that your 250 seeds comprise a random sample of the population.

We can simulate samples obtained using your hypothetical design by drawing values without replacement from the population.

```{r}
#set the seed to have findings replicate 
set.seed(40221)
# draw a random sample of seeds
sample <- population[sample(nrow(population), 250), ]
```


# **Question 3**  (2 Point)

```{r}
#this is us using the mean function to calculate the mean and assigning the value to mean_samp_dia
mean_samp_dia<- mean(sample$diameter)
#this is us printing the value
mean_samp_dia
```

Calculate the mean diameter of seeds in the simulated sample.

You should see above that the sample mean is close to the population mean. In fact, all sample statistics are close to the population; this can be seen by comparing the distribution of sample values with the distribution of population values.

```{r, message=FALSE, warning=FALSE}
# Plot sample vs population using gg plot 
library(patchwork)
#make sure to assign those plots to an object so you can reference them in below lines. Assigning will help us with aligning two plots side by side
p1 <- ggplot(sample, aes(x = diameter)) +
  geom_histogram(bins = 20, alpha = 0.8) +
  geom_vline(xintercept = mean(sample$diameter), color = "blue") +
  labs(x = "Diameter (mm)", y = "Number of seeds in sample") +
  xlim(0, 6)
#make sure to assign those plots to an object so you can reference them in below lines. Assigning will help us with aligning two plots side by side
p2 <- ggplot(population, aes(x = diameter)) +
  geom_histogram(bins = 20, alpha = 0.8) +
  geom_vline(xintercept = mean_pop_diameter, color = "blue") +
  labs(x = "Diameter (mm)", y = "Number of seeds in population") +
  xlim(0, 6)
#this is how we can plot two plots side by side
p1 | p2
```
While there are some small differences, the overall shape is similar and the sample mean is almost exactly the same as the population mean. So with this sampling design, you obtained a dataset with few distortions of the population properties, and the sample mean is a good estimate of the population mean.

### Assessing bias through simulation

You may wonder: does that happen all the time, or was this just a lucky draw? This question can be answered by simulating a large number of samples and checking the average behavior to see whether the undistorted representation of the population is typical for this sampling design.

The cell below estimates the bias, Standard Error, and root mean squared error (RMSE) of the sample mean by:

drawing 1000 samples of size 300;
storing the sample mean from each sample;


* The **bias** of the sample mean is its average distance from the population mean.
* **Standard Error**: standard deviation of the sample means across all 1000 samples.
* **RMSE**  measures how much the sample mean deviates from the population mean on average, combining both variance and bias.

We can estimate these using our simulation results as follows:

```{r}
#this is us setting the seed so we can have replicated findings 
set.seed(40221)
#this is us assigning the value of 1000 to nsims, which is the number of simulations 
nsim <- 1000
#this is use creating a emplty column called samp_means,which has the legnth of nsims, using the numeric function 
samp_means <- numeric(nsim)

#this is us creating a for loop - a programming structure that allows you to execute a block of code repeatedly, typically for a known number of times or while iterating over a sequence of items. i is defined by the number of simulations, such that one simulation is an i. Technically you will have 1000. Such that you will draw 1000 samples of 250 seeds!Also, we are calculating and assigning the mean diameter of seeds to  samp_means for each i (1000)
for(i in 1:nsim) {
  samp <- population[sample(nrow(population), 250), ]
  samp_means[i] <- mean(samp$diameter)
}

# Estimate bias
bias<-mean(samp_means) - mean_pop_diameter

# Standard deviation of sample means (Standard Error)
se<-sd(samp_means)

# RMSE
rmse<-sqrt(mean((samp_means - mean_pop_diameter)^2))
list("Bias"=bias, "Standard Error"=se ,"RMSE"=rmse)
```
* So the average error observed in 1000 simulations was about 0.001 mm! This suggests that the sample mean is unbiased: on average, there is no error. Therefore, at least with respect to estimating the population mean, random samples appear to be unbiased samples.

* So on average, the sample mean varies by about 0.04 mm from sample to sample.

* Note that the root mean squared error (RMSE) is very close to the variance of the sample mean across simulations, but not exactly the same; this latter calculation measures the spread around the population mean, and is a conventional measure of estimation accuracy.

```{r}
# Plot sampling distribution
ggplot(data.frame(sample_mean = samp_means), aes(x = sample_mean)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = mean_pop_diameter, color = "blue") +
  labs(x = "Value of sample mean", y = "Number of simulations")
```

## Biased sampling

In this scenario, you'll use the same hypothetical population of eucalyptus seed diameter measurements and explore the impact of a biased sampling design.

In the first design, you were asked to imagine that you collected and sifted plant material to obtain seeds. Suppose you didn't know that the typical seed is about 1 mm in diameter and decided to use a sieve that is a little too coarse, tending only to sift out larger seeds and letting smaller seeds pass through. As a result, small seeds have a lower probability of being included in the sample and large seeds have a higher probability of being included in the sample.

This kind of sampling design can be described by assigning differential *sampling weights* $w_1,...,w_N$ to each observation. The cell below defines some hypothetical weights such that larger diameters are more likely to be sampled.

```{r}
# inclusion weight function
#x: the input variable (can be a number or a vector).
#	r: the rate of growth or “steepness” of the curve (default 10).
# c: the center or midpoint of the curve (default 1.5).
# exp(-r * (x - c)): creates the exponential term that determines how quickly the function transitions from 0 to 1.

weight_fn <- function(x, r = 10, c = 1.5) {
  1 / (1 + exp(-r * (x - c)))
}

# Plot weight function
grid <- seq(0, 6, length.out = 100)
weight_df <- data.frame(
  seed_diameter = grid,
  weight = weight_fn(grid)
)

ggplot(weight_df, aes(x = seed_diameter, y = weight)) +
  geom_area(alpha = 0.3, linetype = "solid") +
  labs(x = "Seed diameter", y = "Weight") +
  theme(plot.margin = margin(t = 5, r = 5, b = 5, l = 5, unit = "pt"))
```

The actual probability that a seed is included in the sample -- its **inclusion probability** -- is proportional to the sampling weight. These inclusion probabilities $\pi_i$ can be calculated by normalizing the weights $w_i$ over all seeds in the population $\pi_i=\frac{w_i}{\sum_i w_i}$:

It may help you to picture how the weights will be used in sampling to line up this plot with the population distribution. In effect, we will sample more from the right tail of the population distribution, where the weight is nearest to 1.

* The following cell draws a sample with replacement from the hypothetical seed population with seeds weighted according to the inclusion probability given by the function above.

```{r}
# Assign weights and sample
#In the first step we are creating another data frame because we are manipulating the original data frame
population_mod1 <- population

# We apply the weight function that was created in lines 257 to 259 to the diameter of seeds
population_mod1$weight <- weight_fn(population_mod1$diameter)

#make sure you set the seed to get the replication of findings 
set.seed(40721)

# we are creating a second sample (sample2) data frame of draws from the population mod 1 data frame with 250 nrows,we rename weight to "prob"
sample2 <- population_mod1[sample(nrow(population_mod1), 250, prob = population_mod1$weight), ]
```


# **Question 4**   (2 Point)

Calculate the mean diameter of seeds in the simulated sample and store the value as `mean_sample2_diameter`.

```{r}
#this is us calculating the mean for sample2 seed diameter
mean_sample2_diameter <- mean(sample2$diameter)

#this is us printing the mean sample diameter
mean_sample2_diameter
```



# **Question 5**    (4 Point)

Show side-by-side plots of the distribution of sample values and the distribution of population values, with vertical lines indicating the corresponding mean on each plot.
:::
*Hint*: Replace sample with sample2. Utilizing different methods is also welcome.


```{r, message=FALSE, warning=FALSE}
###########Replace "sample" with "sample2". Utilizing different methods is also welcome.#########

########Change the name of the plots. We do not want to write over any previously created plots###########

# Plot sample vs population
library(patchwork)

p1 <- ggplot(sample, aes(x = diameter)) +
  geom_histogram(bins = 20, alpha = 0.8) +
  geom_vline(xintercept = mean(sample$diameter), color = "blue") +
  labs(x = "Diameter (mm)", y = "Number of seeds in sample") +
  xlim(0, 6)

p2 <- ggplot(population, aes(x = diameter)) +
  geom_histogram(bins = 20, alpha = 0.8) +
  geom_vline(xintercept = mean_pop_diameter, color = "blue") +
  labs(x = "Diameter (mm)", y = "Number of seeds in population") +
  xlim(0, 6)

p1 | p2
```

### Assessing bias through simulation


# **Question 6** (5 Points)

- Investigate the bias, standard error and RMSE of the sample mean by:

- drawing 1000 samples with observations weighted by inclusion probability;

- storing the collection of sample means from each sample as samp_means;
compute  `bias1`, `se1` and `rmse1`.


(**Hint**: copy the cell that performs this simulation in scenario 1, and be sure to replace population with population_mod1 and adjust the sampling step to include weights = ... with the appropriate argument.)


```{r}
#this is us setting the seed so we can have replicated findings 
set.seed(40221)
#this is us assigning the value of 1000 to nsims, which is the number of simulations 
nsim <- 1000
#this is use creating a emplty column called samp_means,which has the legnth of nsims, using the numeric function 
samp_means <- numeric(nsim)

#this is us creating a for loop - a programming structure that allows you to execute a block of code repeatedly, typically for a known number of times or while iterating over a sequence of items. i is defined by the number of simulations, such that one simulation is an i. Technically you will have 1000. Such that you will draw 1000 samples of 250 seeds!Also, we are calculating and assigning the mean diameter of seeds to  samp_means for each i (1000)
for(i in 1:nsim) {
  samp <- population[sample(nrow(population), 250), ]
  samp_means[i] <- mean(samp$diameter)
}

#########ADD WEIGHTS TO YOUR DATAFRAME
# We apply the weight function that was created in lines 257 to 259 to the diameter of seeds. Change the data frame name!#################
population_mod1$weight <- weight_fn(population_mod1$diameter)

### Note make sure to take a look at your new data frame to ensure that "weight was added! ###

# Estimate bias
bias<-mean(samp_means) - mean_pop_diameter

# Standard deviation of sample means (Standard Error)
se<-sd(samp_means)

# RMSE
rmse<-sqrt(mean((samp_means - mean_pop_diameter)^2))
list("Bias"=bias, "Standard Error"=se ,"RMSE"=rmse)
```
 
# **Question 7** (3 Points)

Does this sampling design seem to introduce bias? If so, does the sample mean tend to over-estimate or under-estimate the population mean? and interpret and compare the Standard Error and RMSE.

:::

`r bfcolor("Replace this line with your answers:", "red")` \


# Scenario 2: hawks

In this scenario, you'll explore sampling from a population with group structure -- frequently bias can arise from inadvertent uneven sampling of groups within a population.

## Hypothetical population

Suppose you're interested in determining the average beak-to-tail length of red-tailed hawks to help differentiate them from other hawks by sight at a distance. Females and males differ slightly in length -- females are generally larger than males. The cell below generates length measurements for a hypothetical population of 3000 females and 2000 males.

```{r,message=FALSE, warning=FALSE}
# this is us setting the seed
set.seed(40721)

# this us creating a dataframe for females of from a normal distrubution (rnorm) of 3000 with a mean of 57.5 and sd of 3. We set sex as female using  sex = "female"

female_hawks <- data.frame(
  length = rnorm(3000, mean = 57.5, sd = 3),
  sex = "female"
)

# this us creating a dataframe for males of from a normal distrubution (rnorm) of 2000 with a mean of 57.5 and sd of 3. We set sex as female using  sex = "male"
male_hawks <- data.frame(
  length = rnorm(2000, mean = 50.5, sd = 3),
  sex = "male"
)

#this is us using the rbind function to combine the rows of the two newly created data frames

population_hawks <- rbind(female_hawks, male_hawks)

#this is me printing the first couple of observations  

head(population_hawks[order(population_hawks$sex), ], 4)

```


The cell below produces a histogram of the lengths in the population overall (bottom panel) and when distinguished by sex (top panel).

```{r, message=FALSE, warning=FALSE}
# Plot distributions
p1 <- ggplot(population_hawks, aes(x = length, fill = sex)) +
  geom_histogram(alpha = 0.5, position = "identity", bins = 40) +
  xlim(40, 70) +
  labs(x = "length (cm)", y = "number of birds")

p2 <- ggplot(population_hawks, aes(x = length)) +
  geom_histogram(bins = 40, fill = "red", alpha = 0.5) +
  xlim(40, 70) +
  labs(x = "length (cm)", y = "number of birds")

p1 / p2
```

The population mean -- average length of both female and male red-tailed hawks -- is shown below.

```{r}
# Population mean
mean(population_hawks$length)
```
First try drawing a random sample from the population:
```{r}
# Random sample
set.seed(40821)
sample_hawks <- population_hawks[sample(nrow(population_hawks), 300), ]
```


# **Question 8** (4 Points) 

- Do you expect that the sample will contain equal numbers of male and female hawks?

- compute the proportions of individuals in the sample of each sex and store the result as a dataframe named `proportion_hawks_sample`

```{r}
#this is us creating a table of proportions using the table fucntion and then making the table and then requesting proportions. We change the table into a data frame using the as.data.frame function and lastly assign the data frame to proportion_hawks_sample

proportion_hawks_sample <- as.data.frame(prop.table(table(sample_hawks$sex)))

#this is us assingning columns name by fist concatinating "sex" and "propotion" and then assigning those characters to columns using  the colnames argument

colnames(proportion_hawks_sample) <- c("sex", "proportion")

#this is us printing the table
proportion_hawks_sample
```


**Hint**: group by sex, use .count(), and divide by the sample size. Be sure to rename the output column appropriately, as the default behavior produces a column called length.

`r bfcolor("Replace this line with your answers:", "red")` \


## Biased sampling

```{r, message=FALSE, warning=FALSE}
weight_fn <- function(sex, p = 5/6) {
  ifelse(sex == "male", p, 1 - p)
}

weight_df <- data.frame(
  length = c(50.5, 57.5),
  weight = c(5/6, 1/6),
  sex = c("male", "female")
)

p1 <- ggplot(population_hawks, aes(x = length, fill = sex)) +
  geom_histogram(alpha = 0.5, position = "identity", bins = 40) +
  xlim(40, 70) +
  labs(x = "length (cm)", y = "number of birds")

p2 <- ggplot(weight_df, aes(x = length, y = weight, fill = sex)) +
  geom_col(alpha = 0.5) +
  xlim(40, 70) +
  ylim(0, 1) +
  labs(x = "length (cm)", y = "weight")

p1 / p2
```

:::{.callout-important}

# **Question 9** (2 Points)

Draw a weighted sample `sample_hawks_biased` from the population `population_hawks` using the weights defined by `weight_fn`, and compute and store the value of the sample mean as `sample_hawks_biased_mean`.
:::

`r bfcolor("Replace this line with your answers:", "red")` \

:::{.callout-important}
# **Question 10** (4 Points)

Investigate the bias of the sample mean by:

- drawing 1000 samples with observations weighted by `weight_fn`;

- storing the sample mean from each sample as `samp_means_hawks`;

- compute the  `bias1`, `se1` and `rmse1`, and comment.
:::


`r bfcolor("Replace this line with your answers:", "red")` \